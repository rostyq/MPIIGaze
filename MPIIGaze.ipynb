{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather Data from Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_files = glob.glob('./dataset/Data/Normalized/**/*.mat', recursive=True)\n",
    "mat_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices, IMG, POSE, GAZE = gather_data('./dataset/Data/Normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAZE = gaze3Dto2D(GAZE)\n",
    "POSE = pose3Dto2D(POSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((213658, 36, 60, 1), (213658, 2), (213658, 2), (213658, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG.shape, POSE.shape, GAZE.shape, indices.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p00' 'day01' '0001.jpg']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=60x36 at 0x1129C5518>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "print(indices[i])\n",
    "Image.fromarray(IMG[i].reshape((36, 60)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPool2D, Dense, Concatenate, Flatten\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "input_img = Input(shape=(36, 60, 1), name='InputNormalizedImage')\n",
    "input_pose = Input(shape=(2,), name='InputHeadPose')\n",
    "\n",
    "# convolutional\n",
    "conv1 = Conv2D(filters=20,\n",
    "               kernel_size=(5, 5),\n",
    "               strides=(1, 1),\n",
    "               kernel_initializer=RandomNormal(mean=0.0, stddev=0.1, seed=None),\n",
    "               bias_initializer='zeros',\n",
    "               name='conv1'\n",
    "              )(input_img)\n",
    "pool1 = MaxPool2D(pool_size=(2, 2),\n",
    "                  strides=(2, 2),\n",
    "                  padding='valid',\n",
    "                  name='maxpool1'\n",
    "                 )(conv1)\n",
    "conv2 = Conv2D(filters=50,\n",
    "               kernel_size=(5, 5),\n",
    "               strides=(1, 1),\n",
    "               kernel_initializer=RandomNormal(mean=0.0, stddev=0.01, seed=None),\n",
    "               bias_initializer='zeros',\n",
    "               name='conv2'\n",
    "              )(pool1)\n",
    "pool2 = MaxPool2D(pool_size=(2, 2),\n",
    "                  strides=(2, 2),\n",
    "                  padding='valid',\n",
    "                  name='maxpool2'\n",
    "                 )(conv2)\n",
    "\n",
    "flatt = Flatten(name='flatt')(pool2)\n",
    "\n",
    "# inner product 1\n",
    "dense1 = Dense(units=500,\n",
    "              activation='relu',\n",
    "              kernel_initializer='glorot_uniform',\n",
    "              bias_initializer='zeros',\n",
    "              name='ip1'\n",
    "             )(flatt)\n",
    "\n",
    "# concatanate with head pose\n",
    "cat = Concatenate(axis=-1, name='concat')([dense1, input_pose])\n",
    "\n",
    "# inner product 2\n",
    "dense2 = Dense(units=2,\n",
    "              kernel_initializer='glorot_uniform',\n",
    "              bias_initializer='zeros',\n",
    "              name='ip2'\n",
    "             )(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([input_img, input_pose], dense2)\n",
    "model.compile(optimizer='adam', loss=euclidean_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbCallBack = TensorBoard(log_dir='./log',\n",
    "                         histogram_freq=0,\n",
    "                         write_graph=True,\n",
    "                         write_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 149560 samples, validate on 64098 samples\n",
      "Epoch 1/3\n",
      "149560/149560 [==============================] - 533s 4ms/step - loss: 2325.2116 - val_loss: 23.0804\n",
      "Epoch 2/3\n",
      "149560/149560 [==============================] - 543s 4ms/step - loss: 31.7360 - val_loss: 9.2443\n",
      "Epoch 3/3\n",
      "149560/149560 [==============================] - 551s 4ms/step - loss: 4.2522 - val_loss: 6.9708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1196d1c88>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[IMG, POSE], y=GAZE,\n",
    "          batch_size=1000,\n",
    "          shuffle=True,\n",
    "          epochs=3,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
